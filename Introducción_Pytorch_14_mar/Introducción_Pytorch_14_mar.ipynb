{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNsa-hmja1h-"
   },
   "source": [
    "# Ejercicio de introducción a Pytorch\n",
    "Haremos un recorrido por los aspectos fundamentales de pytroch desde el manejo de tensores hasta el entrenamiento y evaluación de una red neuronal. \n",
    "Para completarlo podemos consultar\n",
    " [ESTE](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.ipynb#scrollTo=u-L7YQmcHvX8) cuaderno.y otros recursos dados a lo largo del cuaderno.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POmirEwBbj1P"
   },
   "source": [
    "Primero importamos algunas librerías básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YlhqXdgsF7fC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prestamour\\AppData\\Local\\Temp\\ipykernel_9008\\3787987072.py:11: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UtUr7QYZHon3"
   },
   "outputs": [],
   "source": [
    "#Pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdbqZ1kazh4b"
   },
   "source": [
    "Primero recordemos algunas funcionalidades de los tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9W98Co-sapv",
    "outputId": "e2198074-36fb-4645-90d8-becfb1b89f8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0493, 0.3038, 0.7319],\n",
       "         [0.7723, 0.3339, 0.2409],\n",
       "         [0.0704, 0.3034, 0.0284],\n",
       "         ...,\n",
       "         [0.3628, 0.5471, 0.1506],\n",
       "         [0.2785, 0.3361, 0.6088],\n",
       "         [0.9496, 0.7048, 0.3124]],\n",
       "\n",
       "        [[0.7132, 0.8051, 0.2585],\n",
       "         [0.8906, 0.2785, 0.5699],\n",
       "         [0.7391, 0.2114, 0.8441],\n",
       "         ...,\n",
       "         [0.3412, 0.2594, 0.8107],\n",
       "         [0.7168, 0.9299, 0.5241],\n",
       "         [0.5767, 0.1828, 0.9871]],\n",
       "\n",
       "        [[0.2587, 0.8864, 0.2999],\n",
       "         [0.1338, 0.7250, 0.2669],\n",
       "         [0.2096, 0.4833, 0.9208],\n",
       "         ...,\n",
       "         [0.1417, 0.5501, 0.1718],\n",
       "         [0.2127, 0.9041, 0.1990],\n",
       "         [0.0530, 0.2265, 0.7527]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5584, 0.7162, 0.2761],\n",
       "         [0.1078, 0.5252, 0.0872],\n",
       "         [0.0648, 0.3773, 0.9389],\n",
       "         ...,\n",
       "         [0.7418, 0.2400, 0.9020],\n",
       "         [0.8031, 0.0098, 0.9031],\n",
       "         [0.2347, 0.9169, 0.6531]],\n",
       "\n",
       "        [[0.4604, 0.5113, 0.1537],\n",
       "         [0.5396, 0.8254, 0.7320],\n",
       "         [0.8253, 0.6028, 0.5587],\n",
       "         ...,\n",
       "         [0.9943, 0.1710, 0.5543],\n",
       "         [0.2798, 0.1425, 0.2855],\n",
       "         [0.3945, 0.2644, 0.6756]],\n",
       "\n",
       "        [[0.0689, 0.0649, 0.0591],\n",
       "         [0.9019, 0.9428, 0.6891],\n",
       "         [0.2256, 0.9693, 0.2261],\n",
       "         ...,\n",
       "         [0.7105, 0.4479, 0.9868],\n",
       "         [0.5132, 0.1098, 0.0594],\n",
       "         [0.8545, 0.7406, 0.0194]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generar un arreglo en numpy.array\n",
    "#\n",
    "t = torch.rand(100,110, 3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LGQ0J7fsh0G",
    "outputId": "8d68890e-5140-4349-ee86-21373bd7fdae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0493, 0.7723, 0.0704,  ..., 0.3628, 0.2785, 0.9496],\n",
       "         [0.3038, 0.3339, 0.3034,  ..., 0.5471, 0.3361, 0.7048],\n",
       "         [0.7319, 0.2409, 0.0284,  ..., 0.1506, 0.6088, 0.3124]],\n",
       "\n",
       "        [[0.7132, 0.8906, 0.7391,  ..., 0.3412, 0.7168, 0.5767],\n",
       "         [0.8051, 0.2785, 0.2114,  ..., 0.2594, 0.9299, 0.1828],\n",
       "         [0.2585, 0.5699, 0.8441,  ..., 0.8107, 0.5241, 0.9871]],\n",
       "\n",
       "        [[0.2587, 0.1338, 0.2096,  ..., 0.1417, 0.2127, 0.0530],\n",
       "         [0.8864, 0.7250, 0.4833,  ..., 0.5501, 0.9041, 0.2265],\n",
       "         [0.2999, 0.2669, 0.9208,  ..., 0.1718, 0.1990, 0.7527]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5584, 0.1078, 0.0648,  ..., 0.7418, 0.8031, 0.2347],\n",
       "         [0.7162, 0.5252, 0.3773,  ..., 0.2400, 0.0098, 0.9169],\n",
       "         [0.2761, 0.0872, 0.9389,  ..., 0.9020, 0.9031, 0.6531]],\n",
       "\n",
       "        [[0.4604, 0.5396, 0.8253,  ..., 0.9943, 0.2798, 0.3945],\n",
       "         [0.5113, 0.8254, 0.6028,  ..., 0.1710, 0.1425, 0.2644],\n",
       "         [0.1537, 0.7320, 0.5587,  ..., 0.5543, 0.2855, 0.6756]],\n",
       "\n",
       "        [[0.0689, 0.9019, 0.2256,  ..., 0.7105, 0.5132, 0.8545],\n",
       "         [0.0649, 0.9428, 0.9693,  ..., 0.4479, 0.1098, 0.7406],\n",
       "         [0.0591, 0.6891, 0.2261,  ..., 0.9868, 0.0594, 0.0194]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se realizan permutaciones sobre las 3 dimensiones \n",
    "# torch.permute(t, (0,3,2,1))\n",
    "torch.permute(t, (0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYtN-PDlzhSP",
    "outputId": "6eb305f4-876e-42ba-a931-e37570846b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primero: tensor([[0.7224, 0.7452, 0.5345],\n",
      "        [0.5726, 0.8326, 0.3212],\n",
      "        [0.4844, 0.3904, 0.3614]])\n",
      "Segundo: tensor([[ 1.8120, -0.6998,  1.8591],\n",
      "        [-0.0344,  1.7919, -2.7798],\n",
      "        [ 0.8137, -0.0143, -0.2423]])\n",
      "Primero Tamaño: torch.Size([3, 3])\n",
      "Segundo Tamaño: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Crear un tensor aleatorio con entradas entre 0 y 1, de tamaño 3x3\n",
    "primer_tensor = torch.rand(3, 3)\n",
    "\n",
    "# Crear un tensor de tamaño 3x3 con valores en una distribución normal estandar\n",
    "segundo_tensor = torch.randn(3,3)\n",
    "# Calcular el tamaño de los tensores\n",
    "tensor_size1 = primer_tensor.size()\n",
    "tensor_size2 = segundo_tensor.size()\n",
    "\n",
    "# Imprimir los valores de los vectores y su tamaño\n",
    "print('Primero:',primer_tensor)\n",
    "print('Segundo:',segundo_tensor)\n",
    "print('Primero Tamaño:',tensor_size1)\n",
    "print('Segundo Tamaño:',tensor_size2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-FGFp5HhNhkY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplicacion matmul:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "multiplicacion *:\n",
      " tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Crear una matriz de unos de tamaño 3 by 3\n",
    "tensor_of_ones = torch.ones(3, 3)\n",
    "\n",
    "# Crear una matrix identidad de tamaño 3 by 3\n",
    "identity_tensor = torch.diag(torch.ones(3))\n",
    "\n",
    "# Multiplicar las dos matrices anteriores\n",
    "matrices_multiplied = torch.matmul(tensor_of_ones, identity_tensor)\n",
    "print('multiplicacion matmul:\\n',matrices_multiplied)\n",
    "\n",
    "\n",
    "# ¿Qué ocurre si las multiplica usando * ?\n",
    "# Se multiplica entrada por entrada entre matrices\n",
    "print('multiplicacion *:\\n',tensor_of_ones *identity_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNwlCf3PTdFX"
   },
   "source": [
    "### Cálculo de gradientes\n",
    "Calculemos un gradiente utilizando Pytorch. La función está en la gráfica Graph0.\n",
    "\n",
    "Para esto, puede ir a la sección Dynamic Computation Graph and Backpropagation, del cuaderno inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exfqwUo0Oyb-",
    "outputId": "63d2103c-ac97-4f33-b2df-17e26ce4eef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of x is: tensor(5.)\n",
      "Gradient of y is: tensor(5.)\n",
      "Gradient of z is: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Initialize x, y and z to values 4, -3 and 5\n",
    "x = torch.tensor(4., requires_grad=True) # Solo flotantes tienen gradientes\n",
    "y = torch.tensor(-3., requires_grad=True)\n",
    "z = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "# Set q to sum of x and y, set f to product of q with z\n",
    "q = x+y\n",
    "f = q*z\n",
    "\n",
    "# Compute the derivatives\n",
    "f.backward()\n",
    "\n",
    "# Print the gradients\n",
    "print(\"Gradient of x is: \" + str(x.grad))\n",
    "print(\"Gradient of y is: \" + str(y.grad))\n",
    "print(\"Gradient of z is: \" + str(z.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ssM9jMBbS1c"
   },
   "source": [
    "Ahora calculemos los gradientes para la función descrita en la imagen Graph1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "xuyomr_DZsOK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 100])\n",
      "torch.Size([1000, 1000])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (100) must match the size of tensor b (1000) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(z\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(q\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m---> 12\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mz\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mq\u001b[49m\n\u001b[0;32m     14\u001b[0m mean_f \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(f)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Calcular los gradientes\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (1000) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Initializar x,y,z como tensores aleatorios de tamaño (1000,100)\n",
    "x = torch.rand(1000,100).requires_grad_(True)\n",
    "y = torch.rand(1000,100).requires_grad_(True)\n",
    "z = torch.rand(1000,100).requires_grad_(True)\n",
    "\n",
    "# Multiplicar los tensores x con y\n",
    "q = torch.matmul(x,y.permute(1, 0))\n",
    "\n",
    "# Multiplicar componente a componente los tensores z con q\n",
    "print(z.size())\n",
    "print(q.size())\n",
    "f = z*q\n",
    "\n",
    "mean_f = torch.mean(f)\n",
    "\n",
    "# Calcular los gradientes\n",
    "f.backward()\n",
    "print(\"Gradient of x is: \" + str(x.grad))\n",
    "print(\"Gradient of y is: \" + str(y.grad))\n",
    "print(\"Gradient of z is: \" + str(z.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8h8oiEp3eWTU"
   },
   "source": [
    "### Construcción de redes neuronales con Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEH8zLXhazmN"
   },
   "source": [
    "Construimos una red neuronal en Pytorch de forma *manual*. la entrada serán imágenes de tamaño (28,28). Es decir contienen pixeles de 784 pixeles. \n",
    "La red contendrá una capa de entrada, una capa oculta con 200 unidades y una capa de salida con 10 categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXjt0ggwGWbb",
    "outputId": "0acd0bcf-8784-4dba-bddc-b1107d400790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([19131.3672, 20204.4238, 18687.9414, 19228.6797, 18110.9297, 20629.4805,\n",
      "        19915.1660, 19351.3867, 20788.6504, 19822.7949])\n"
     ]
    }
   ],
   "source": [
    "input_layer=torch.rand(784)\n",
    "# Inicializar los pesos de la red neuronal\n",
    "weight_1 = torch.rand(784,200)\n",
    "weight_2 = torch.rand(200,10)\n",
    "\n",
    "# Multiplicar la capa de entrada con el peso 1\n",
    "hidden_1 = torch.matmul(input_layer,weight_1)\n",
    "\n",
    "# Multiplicar la capa oculta con el peso 2\n",
    "output_layer = torch.matmul(hidden_1,weight_2)\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54kg7I1udw5p"
   },
   "source": [
    "Ahora construimos la misma rede neuronal pero utilizando los módulos de Pytorch. (Ver sección *The model* del cuaderno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "7bb9bFrzHBhT"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Inicializar las dos capas lineales \n",
    "        self.fc1 = nn.Linear(784,200)\n",
    "        self.fc2 = nn.Linear(200,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        # Usar las capas inicializadas y devolver x\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mM-RqOEQfjb4"
   },
   "source": [
    "Construyamos la red neuronal en la gráfica NN1 dada ede forma *manual*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4CXMDaaHjym"
   },
   "outputs": [],
   "source": [
    "# Crear tensor aleatorio como capa de entrada\n",
    "input_layer= torch.rand(784)\n",
    "\n",
    "# Crear matrices de pesos\n",
    "weight_1= ___\n",
    "weight_2= ___\n",
    "weight_3= ___\n",
    "\n",
    "# Calcular la primera y segunda capa oculta\n",
    "\n",
    "hidden_1 = ___\n",
    "hidden_2 = ___\n",
    "\n",
    "# Imprimir la salida\n",
    "print(torch.matmul(__,__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSbwtRcygzpw"
   },
   "source": [
    "La anterior era una red neuronal con 2 capas ocultas ocultas en donde no se aplica ninguna función no-lineal. Veamos que ésta se puede construir con una sola capa oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUVgFxvSgvHc"
   },
   "outputs": [],
   "source": [
    "# Calcular la compuesta de las matrices de pesos\n",
    "weight_composed_1 = torch.matmul(__,__)\n",
    "weight = torch.matmul(__,__)\n",
    "\n",
    "# Multiplicar la capa de entrada por weight e imprimir\n",
    "print(__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLcs6NtUlo-f"
   },
   "source": [
    "## Entrenamiendo de una red neuronal para reconocimiento de dígitos (MNIST Dataset)\n",
    "### Preparar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZkIa4FSl9h-"
   },
   "source": [
    "Para preparar los datos primero creamos un parámetro *transform* para transformarlos. Haremos dos cosas:\n",
    "- Transformar las imágenes del MNIST Dataset a tensores para poder alimentar la red neuronal. Esto lo hacemos con el método ToTensor.\n",
    "- Por otro lado, debemos normalizarlos con respecto a una media y variaza. Esto lo hacemos con el método Normalize. En este caso usaremos una media de 0.1307 y varianza de 0.3081. (Tenga en cuenta que en el MNIST Dataset los pixeles son en escala de grises, por lo cual sólo tienen un canal de código de color.)\n",
    "\n",
    "Para componer ambas transformaciones (Convertir a tensor y normalizar) usamos transforms.Compose ver [AQUÍ](https://www.programcreek.com/python/example/104832/torchvision.transforms.Compose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lg4S9bKLS2vp"
   },
   "outputs": [],
   "source": [
    "# Transformar los datos a tensores y normalizarlos \n",
    "transform = transforms.Compose([transforms.___,\n",
    "\t\t\t\t\t\t\t\ttransforms.Normalize((___), ((___)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4of_hxAcrdpi"
   },
   "source": [
    "Ahora definimos el conjunto de entrenamiento y testeo. Torchvision permite cargar datasets conocidos para visión como el MNIST. \n",
    "Para entender y completar los parámetros ver [AQUÍ](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61nyqG7wrSec"
   },
   "outputs": [],
   "source": [
    "# Preparar el training set y testing set\n",
    "trainset = torchvision.datasets.MNIST('mnist', train=___, \n",
    "\t\t\t\t\t\t\t\t\t  download=___, transform=___)\n",
    "testset = ____('mnist',___,___,___)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOxpKc2StPB6"
   },
   "source": [
    "El método DataLoader hace parte de torch.utils.data y permite cargar los datos por lotes de un tamaño definido. Para entender los parámetros ver [AQUÍ](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
    "Preparar los datos para entrenamiento y testeo de manera que se procesen 32 imágenes cada vez y se barajen cada vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCJcCLjytI5_"
   },
   "outputs": [],
   "source": [
    "# Preparar training loader y testing loader. \n",
    "# Usar los parámetros dataset, batch_size, shuffle y num_workers.\n",
    "trainloader = torch.utils.data.DataLoader(___, ___, ___, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(___, ___, ___, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2ZNcnMLvjQr"
   },
   "source": [
    "Construya una clase para una red neuronal que será usada para entrenar el MNIST dataset. El dataset contiene imagenes de dimensiones (28,28,2), así que usted deducirá el tamaño de la capa de entrada. Para las calas ocultas use 200 unidades y para la capa de salida 10 unidades (una por cada categoría (Dígitos del 0 al 9)).\n",
    "Como función de activación use Relu de manera funcional (nn.Functional ya está importado como F).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-v_2od5dVx33"
   },
   "outputs": [],
   "source": [
    "# Define the class Net\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):    \n",
    "    \t# Define all the parameters of the net\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(___, ___)\n",
    "        self.fc2 = ___\n",
    "\n",
    "    def forward(self, x):   \n",
    "    \t# Do the forward pass\n",
    "        x = F.relu(self.__(__))\n",
    "        x = self.__(__)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hW1FzRFVvGFU"
   },
   "source": [
    "###Entrenamiento del modelo\n",
    "\n",
    "Por favor analice cuidadosamente el siguiente código, hasta que quede claro los pasos de entrenamiento y evaluación del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4Hd2AAqwSRX"
   },
   "source": [
    "En primer lugar, revisemos si estamos trabajando en GPU. De lo contrario debemos cambiar el tipo de entorno de ejecución en el menú de Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lSdEYQTvFFX"
   },
   "outputs": [],
   "source": [
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhlAJDQNcJRD"
   },
   "source": [
    "Le daremos nombre a nuestro dispositivo GPU, al cual debemos transferir nuesto modelo y los datos a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIy4UMIGX72j"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrDZ6975w0SZ"
   },
   "source": [
    "Definimos nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yVvkS2lv2eU"
   },
   "outputs": [],
   "source": [
    "model=Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T42H97fqw7O0"
   },
   "source": [
    "Empujamos nuestro modelo al dispositivo GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jOvAocBcv6DD"
   },
   "outputs": [],
   "source": [
    "# Push model to device. Has to be only done once\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0kY1SvaxFep"
   },
   "source": [
    "Definimos el ptimizador y la función de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GVA5xRAv98M"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001) # descenso de gradiente\n",
    "loss_module = nn.CrossEntropyLoss()  #función de costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGIHuKHYxJIh"
   },
   "source": [
    "Entrenamos el modelo, siguiendo los 5 pasos vistos en clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7e83caQwBdJ"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, testloader, loss_module, num_epochs=1):\n",
    "    # Set model to train mode\n",
    "    model.train() \n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for data_inputs, data_labels in testloader:\n",
    "            data_inputs = data_inputs.view(-1, 28 * 28)\n",
    "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device)\n",
    "\n",
    "           \n",
    "            \n",
    "            ## Step 2: Run the model on the input data\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "            \n",
    "            ## Step 3: Calculate the loss\n",
    "            loss = loss_module(preds, data_labels)\n",
    "            \n",
    "            ## Step 4: Perform backpropagation\n",
    "            # Before calculating the gradients, we need to ensure that they are all zero. \n",
    "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "            optimizer.zero_grad() \n",
    "            # Perform backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            ## Step 5: Update the parameters\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxY1U-kkwFIW"
   },
   "outputs": [],
   "source": [
    "train_model(model, optimizer, trainloader, loss_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86WV34CqcfkM"
   },
   "source": [
    "A continuación evaluaremos el desempeño del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KD6Z_tcOcxjI"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total, correct =0,0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "    # Put each image into a vector\n",
    "    inputs = inputs.view(-1, 784)\n",
    "    \n",
    "    # Do the forward pass and get the predictions\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    _, outputs = torch.max(outputs.data, 1) #mayor valor entre los dígitos.\n",
    "    total += labels.size(0)\n",
    "    correct += (outputs == labels).sum().item()\n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
