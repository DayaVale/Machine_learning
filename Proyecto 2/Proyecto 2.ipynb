{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d12e003",
   "metadata": {},
   "source": [
    "# Proyecto 2\n",
    " \n",
    "- *Dayana Valentina Gonzalez Vargas*\n",
    "- *Juan Manuel Ramirez*\n",
    "\n",
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "758eebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46608053",
   "metadata": {},
   "source": [
    "### Cargar los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05f735cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X</th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181338</td>\n",
       "      <td>0.060495</td>\n",
       "      <td>0.187476</td>\n",
       "      <td>0.126197</td>\n",
       "      <td>0.233586</td>\n",
       "      <td>0.107389</td>\n",
       "      <td>0.869088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181338</td>\n",
       "      <td>0.137742</td>\n",
       "      <td>0.023022</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.777344</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>6.226562</td>\n",
       "      <td>6.140625</td>\n",
       "      <td>0.116586</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186897</td>\n",
       "      <td>0.062260</td>\n",
       "      <td>0.195070</td>\n",
       "      <td>0.130847</td>\n",
       "      <td>0.243987</td>\n",
       "      <td>0.113140</td>\n",
       "      <td>1.191767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186897</td>\n",
       "      <td>0.121811</td>\n",
       "      <td>0.018412</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.930339</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.914062</td>\n",
       "      <td>0.144983</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.189102</td>\n",
       "      <td>0.062901</td>\n",
       "      <td>0.204945</td>\n",
       "      <td>0.131422</td>\n",
       "      <td>0.249978</td>\n",
       "      <td>0.118556</td>\n",
       "      <td>1.312690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189102</td>\n",
       "      <td>0.123758</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.332386</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.334783</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.183036</td>\n",
       "      <td>0.060051</td>\n",
       "      <td>0.174115</td>\n",
       "      <td>0.129949</td>\n",
       "      <td>0.236967</td>\n",
       "      <td>0.107017</td>\n",
       "      <td>1.096409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183036</td>\n",
       "      <td>0.128469</td>\n",
       "      <td>0.044693</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>1.012019</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>5.468750</td>\n",
       "      <td>5.382812</td>\n",
       "      <td>0.304910</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.168793</td>\n",
       "      <td>0.057910</td>\n",
       "      <td>0.156266</td>\n",
       "      <td>0.116783</td>\n",
       "      <td>0.216326</td>\n",
       "      <td>0.099543</td>\n",
       "      <td>1.386837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168793</td>\n",
       "      <td>0.109720</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.228795</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.306777</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  X  meanfreq        sd    median       Q25  \\\n",
       "0             0           1  1  0.181338  0.060495  0.187476  0.126197   \n",
       "1             1           2  2  0.186897  0.062260  0.195070  0.130847   \n",
       "2             2           3  3  0.189102  0.062901  0.204945  0.131422   \n",
       "3             4           5  5  0.183036  0.060051  0.174115  0.129949   \n",
       "4             5           6  6  0.168793  0.057910  0.156266  0.116783   \n",
       "\n",
       "        Q75       IQR      skew  ...  centroid   meanfun    minfun    maxfun  \\\n",
       "0  0.233586  0.107389  0.869088  ...  0.181338  0.137742  0.023022  0.271186   \n",
       "1  0.243987  0.113140  1.191767  ...  0.186897  0.121811  0.018412  0.271186   \n",
       "2  0.249978  0.118556  1.312690  ...  0.189102  0.123758  0.083333  0.262295   \n",
       "3  0.236967  0.107017  1.096409  ...  0.183036  0.128469  0.044693  0.258065   \n",
       "4  0.216326  0.099543  1.386837  ...  0.168793  0.109720  0.022472  0.235294   \n",
       "\n",
       "    meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.777344  0.085938  6.226562  6.140625  0.116586    sad  \n",
       "1  0.930339  0.085938  4.000000  3.914062  0.144983    sad  \n",
       "2  0.332386  0.085938  0.625000  0.539062  0.334783    sad  \n",
       "3  1.012019  0.085938  5.468750  5.382812  0.304910    sad  \n",
       "4  0.228795  0.093750  0.750000  0.656250  0.306777    sad  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('emotions_by_voice_registers.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11221211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 909 entries, 0 to 908\n",
      "Data columns (total 24 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0.1  909 non-null    int64  \n",
      " 1   Unnamed: 0    909 non-null    int64  \n",
      " 2   X             909 non-null    int64  \n",
      " 3   meanfreq      909 non-null    float64\n",
      " 4   sd            909 non-null    float64\n",
      " 5   median        909 non-null    float64\n",
      " 6   Q25           909 non-null    float64\n",
      " 7   Q75           909 non-null    float64\n",
      " 8   IQR           909 non-null    float64\n",
      " 9   skew          909 non-null    float64\n",
      " 10  kurt          909 non-null    float64\n",
      " 11  sp.ent        909 non-null    float64\n",
      " 12  sfm           909 non-null    float64\n",
      " 13  mode          909 non-null    float64\n",
      " 14  centroid      909 non-null    float64\n",
      " 15  meanfun       909 non-null    float64\n",
      " 16  minfun        909 non-null    float64\n",
      " 17  maxfun        909 non-null    float64\n",
      " 18  meandom       909 non-null    float64\n",
      " 19  mindom        909 non-null    float64\n",
      " 20  maxdom        909 non-null    float64\n",
      " 21  dfrange       909 non-null    float64\n",
      " 22  modindx       909 non-null    float64\n",
      " 23  label         909 non-null    object \n",
      "dtypes: float64(20), int64(3), object(1)\n",
      "memory usage: 170.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65463186",
   "metadata": {},
   "source": [
    "### Eliminación de datos que no son necesarios o son de tipo indíce.\n",
    "Eliminaremos los datos del DataSet que son tipo indíce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "256456ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181338</td>\n",
       "      <td>0.060495</td>\n",
       "      <td>0.187476</td>\n",
       "      <td>0.126197</td>\n",
       "      <td>0.233586</td>\n",
       "      <td>0.107389</td>\n",
       "      <td>0.869088</td>\n",
       "      <td>2.863717</td>\n",
       "      <td>0.923566</td>\n",
       "      <td>0.307220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181338</td>\n",
       "      <td>0.137742</td>\n",
       "      <td>0.023022</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.777344</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>6.226562</td>\n",
       "      <td>6.140625</td>\n",
       "      <td>0.116586</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.186897</td>\n",
       "      <td>0.062260</td>\n",
       "      <td>0.195070</td>\n",
       "      <td>0.130847</td>\n",
       "      <td>0.243987</td>\n",
       "      <td>0.113140</td>\n",
       "      <td>1.191767</td>\n",
       "      <td>3.878650</td>\n",
       "      <td>0.918848</td>\n",
       "      <td>0.298859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186897</td>\n",
       "      <td>0.121811</td>\n",
       "      <td>0.018412</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.930339</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.914062</td>\n",
       "      <td>0.144983</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.189102</td>\n",
       "      <td>0.062901</td>\n",
       "      <td>0.204945</td>\n",
       "      <td>0.131422</td>\n",
       "      <td>0.249978</td>\n",
       "      <td>0.118556</td>\n",
       "      <td>1.312690</td>\n",
       "      <td>4.589995</td>\n",
       "      <td>0.919519</td>\n",
       "      <td>0.313069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189102</td>\n",
       "      <td>0.123758</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.332386</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.334783</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183036</td>\n",
       "      <td>0.060051</td>\n",
       "      <td>0.174115</td>\n",
       "      <td>0.129949</td>\n",
       "      <td>0.236967</td>\n",
       "      <td>0.107017</td>\n",
       "      <td>1.096409</td>\n",
       "      <td>3.680995</td>\n",
       "      <td>0.921361</td>\n",
       "      <td>0.329295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183036</td>\n",
       "      <td>0.128469</td>\n",
       "      <td>0.044693</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>1.012019</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>5.468750</td>\n",
       "      <td>5.382812</td>\n",
       "      <td>0.304910</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.168793</td>\n",
       "      <td>0.057910</td>\n",
       "      <td>0.156266</td>\n",
       "      <td>0.116783</td>\n",
       "      <td>0.216326</td>\n",
       "      <td>0.099543</td>\n",
       "      <td>1.386837</td>\n",
       "      <td>5.031744</td>\n",
       "      <td>0.926238</td>\n",
       "      <td>0.337047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168793</td>\n",
       "      <td>0.109720</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.228795</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.306777</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "0  0.181338  0.060495  0.187476  0.126197  0.233586  0.107389  0.869088   \n",
       "1  0.186897  0.062260  0.195070  0.130847  0.243987  0.113140  1.191767   \n",
       "2  0.189102  0.062901  0.204945  0.131422  0.249978  0.118556  1.312690   \n",
       "3  0.183036  0.060051  0.174115  0.129949  0.236967  0.107017  1.096409   \n",
       "4  0.168793  0.057910  0.156266  0.116783  0.216326  0.099543  1.386837   \n",
       "\n",
       "       kurt    sp.ent       sfm  ...  centroid   meanfun    minfun    maxfun  \\\n",
       "0  2.863717  0.923566  0.307220  ...  0.181338  0.137742  0.023022  0.271186   \n",
       "1  3.878650  0.918848  0.298859  ...  0.186897  0.121811  0.018412  0.271186   \n",
       "2  4.589995  0.919519  0.313069  ...  0.189102  0.123758  0.083333  0.262295   \n",
       "3  3.680995  0.921361  0.329295  ...  0.183036  0.128469  0.044693  0.258065   \n",
       "4  5.031744  0.926238  0.337047  ...  0.168793  0.109720  0.022472  0.235294   \n",
       "\n",
       "    meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.777344  0.085938  6.226562  6.140625  0.116586    sad  \n",
       "1  0.930339  0.085938  4.000000  3.914062  0.144983    sad  \n",
       "2  0.332386  0.085938  0.625000  0.539062  0.334783    sad  \n",
       "3  1.012019  0.085938  5.468750  5.382812  0.304910    sad  \n",
       "4  0.228795  0.093750  0.750000  0.656250  0.306777    sad  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns = [ 'Unnamed: 0.1', 'Unnamed: 0', 'X'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11554258",
   "metadata": {},
   "source": [
    "**Dividimos en dos, el primer conjuntos Y es el conjunto con la etiqueta y el segundo es el conjunto X que va a ser el conjunto de las variables independientes sin la etiqueta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c545914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']\n",
    "y = pd.get_dummies( y, drop_first = True)\n",
    "X = df.drop(columns =['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d89ab6",
   "metadata": {},
   "source": [
    "### Crear los conjuntod de Train, Validación y Test.\n",
    "A partir de la función *train_test_split* vamos a realizarla dos veces, la primera para dividir en test y train. La segunda para ese train anterior dividirlo en val y train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "347d8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test, y_train1, y_test = train_test_split( X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split( X_train1, y_train1, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b6ee0",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1438e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset():\n",
    " \n",
    "  def __init__(self,x,y):\n",
    "    y=y.values\n",
    "    X=x.values\n",
    "    self.X=torch.tensor(X,dtype=torch.float32)\n",
    "    self.y=torch.tensor(y,dtype=torch.float32)\n",
    " \n",
    "  def __len__(self):\n",
    "    return len(self.y)\n",
    "   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.X[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0fc3a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sec=MyDataset(X_train,y_train)\n",
    "test_sec=MyDataset(X_test,y_test)\n",
    "val_sec=MyDataset(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "44ecbc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=DataLoader(\n",
    "    train_sec,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    " )\n",
    "\n",
    "test_data=DataLoader(\n",
    "    test_sec,\n",
    "    batch_size=3,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=None,\n",
    "    pin_memory=False,\n",
    " )\n",
    "\n",
    "val_data=DataLoader(\n",
    "    val_sec,\n",
    "    batch_size=3,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=None,\n",
    "    pin_memory=False,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dcc39dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20]) torch.Size([3, 2])\n",
      "tensor([[0.2276, 0.0391, 0.2321, 0.2119, 0.2580, 0.0461, 2.3979, 9.7464, 0.8642,\n",
      "         0.1852, 0.2336, 0.2276, 0.1917, 0.0584, 0.2759, 0.8516, 0.1484, 4.8438,\n",
      "         4.6953, 0.1747],\n",
      "        [0.2048, 0.0441, 0.2082, 0.1876, 0.2297, 0.0421, 1.9322, 6.3588, 0.8904,\n",
      "         0.3525, 0.2066, 0.2048, 0.1781, 0.0343, 0.2462, 0.6719, 0.0781, 4.4219,\n",
      "         4.3438, 0.1271],\n",
      "        [0.1672, 0.0607, 0.1612, 0.1167, 0.2118, 0.0951, 1.0096, 3.4679, 0.9367,\n",
      "         0.4687, 0.0938, 0.1672, 0.1152, 0.0208, 0.2222, 0.5907, 0.0859, 5.3203,\n",
      "         5.2344, 0.1471]]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "for i, (data, labels) in enumerate(test_data):\n",
    "  print(data.shape, labels.shape)\n",
    "  print(data,labels)\n",
    "  break;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f16d8fe",
   "metadata": {},
   "source": [
    "## Definir la clase NET \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d672f5a6",
   "metadata": {},
   "source": [
    "Se genera la clase NET para construir la red neuronal. Urilizamos 2 capas ocultas para dar mayor adaptabilidad al patron de los datos. Los nodos se establecieron como una reduccion uniforme desde la cantidad de entrada hasta la cantidad de salida. Como funcion de activacion tomamos la tangente hipebolica con el fin de tener una convergencia mas suave alejandonos de casos de sobre entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27a29ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(20,14)\n",
    "        self.fc2 = nn.Linear(14,8)\n",
    "        self.fc3 = nn.Linear(8,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790990c",
   "metadata": {},
   "source": [
    "Para el aprendizaje y evaluacion del modelo se utilizaran las funciones de decenso del gradiente y validacion cruzada en entropia. Se encontro que el decenso del gradiente es la mejor funcion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "73bf18be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net()\n",
    "\n",
    "optimizer= torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion= nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca030d36",
   "metadata": {},
   "source": [
    "**Entrenar el modelo e ir imprimiendo los errores del test y la validación.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0bccb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,optimizer,loss_module,train_loader,valid_loader,num_epochs):\n",
    "  \n",
    "  valid_loss_min =np.inf  #Vamos a encontrar el menor valor de error de validación. Por eso la inicializmaos como 'infinito'\n",
    "  \n",
    "  for i in range(num_epochs):\n",
    "    model.train()  #ponemos el modelo en modo entrenamiento. Es importante en otras arquitecturas como redes convolucionales.\n",
    "    train_loss = 0.0\n",
    "    v_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "         # Reiniciar los gradientes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass: calcular la salida para los datos de entrada..\n",
    "        preds = model(data)\n",
    "        preds = preds.squeeze(dim=1)\n",
    "\n",
    "        # calculate the batch loss\n",
    "        loss = loss_module(preds, target)\n",
    "        \n",
    "        # backpropagation: cálculo de gradientes\n",
    "        loss.backward()\n",
    "   \n",
    "        # actualizar los parámetros\n",
    "        optimizer.step()\n",
    "\n",
    "        # actualizar la cuenta de costos a lo largo de los lotes\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    # for data,labels in testloader:\n",
    "\n",
    "    train_loss = train_loss/len(train_loader.dataset) \n",
    "\n",
    "    model.eval() #Ponemos el modelo en modo evaluación.\n",
    "    \n",
    "    for data,target in valid_loader:\n",
    "      output=model(data)\n",
    "      valid_loss= criterion(output, target)\n",
    "      valid_loss += loss.item()*data.size(0)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    \n",
    "    #imprimir estadísticas de entrenamiento y validación\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        i, train_loss, valid_loss))\n",
    "    \n",
    "\n",
    "    #Guardamos el modelo con el menor error de validación.\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_bikeshare.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d46030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7ac0d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 0.477401 \tValidation Loss: 0.002290\n",
      "Validation loss decreased (inf --> 0.002290).  Saving model ...\n",
      "Epoch: 1 \tTraining Loss: 0.475920 \tValidation Loss: 0.002278\n",
      "Validation loss decreased (0.002290 --> 0.002278).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.474709 \tValidation Loss: 0.002273\n",
      "Validation loss decreased (0.002278 --> 0.002273).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.475487 \tValidation Loss: 0.002274\n",
      "Epoch: 4 \tTraining Loss: 0.475564 \tValidation Loss: 0.002251\n",
      "Validation loss decreased (0.002273 --> 0.002251).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.475435 \tValidation Loss: 0.002253\n",
      "Epoch: 6 \tTraining Loss: 0.478216 \tValidation Loss: 0.002251\n",
      "Epoch: 7 \tTraining Loss: 0.476768 \tValidation Loss: 0.002260\n",
      "Epoch: 8 \tTraining Loss: 0.476634 \tValidation Loss: 0.002245\n",
      "Validation loss decreased (0.002251 --> 0.002245).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.476140 \tValidation Loss: 0.002252\n",
      "Epoch: 10 \tTraining Loss: 0.476721 \tValidation Loss: 0.002253\n",
      "Epoch: 11 \tTraining Loss: 0.476396 \tValidation Loss: 0.002248\n",
      "Epoch: 12 \tTraining Loss: 0.476470 \tValidation Loss: 0.002240\n",
      "Validation loss decreased (0.002245 --> 0.002240).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.476303 \tValidation Loss: 0.002236\n",
      "Validation loss decreased (0.002240 --> 0.002236).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.476168 \tValidation Loss: 0.002231\n",
      "Validation loss decreased (0.002236 --> 0.002231).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.476023 \tValidation Loss: 0.002225\n",
      "Validation loss decreased (0.002231 --> 0.002225).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.475982 \tValidation Loss: 0.002217\n",
      "Validation loss decreased (0.002225 --> 0.002217).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.475879 \tValidation Loss: 0.002211\n",
      "Validation loss decreased (0.002217 --> 0.002211).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.476013 \tValidation Loss: 0.002207\n",
      "Validation loss decreased (0.002211 --> 0.002207).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.475868 \tValidation Loss: 0.002201\n",
      "Validation loss decreased (0.002207 --> 0.002201).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.475690 \tValidation Loss: 0.002193\n",
      "Validation loss decreased (0.002201 --> 0.002193).  Saving model ...\n",
      "Epoch: 21 \tTraining Loss: 0.475541 \tValidation Loss: 0.002189\n",
      "Validation loss decreased (0.002193 --> 0.002189).  Saving model ...\n",
      "Epoch: 22 \tTraining Loss: 0.475439 \tValidation Loss: 0.002185\n",
      "Validation loss decreased (0.002189 --> 0.002185).  Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 0.475467 \tValidation Loss: 0.002177\n",
      "Validation loss decreased (0.002185 --> 0.002177).  Saving model ...\n",
      "Epoch: 24 \tTraining Loss: 0.475453 \tValidation Loss: 0.002173\n",
      "Validation loss decreased (0.002177 --> 0.002173).  Saving model ...\n",
      "Epoch: 25 \tTraining Loss: 0.475311 \tValidation Loss: 0.002165\n",
      "Validation loss decreased (0.002173 --> 0.002165).  Saving model ...\n",
      "Epoch: 26 \tTraining Loss: 0.475180 \tValidation Loss: 0.002159\n",
      "Validation loss decreased (0.002165 --> 0.002159).  Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 0.475051 \tValidation Loss: 0.002150\n",
      "Validation loss decreased (0.002159 --> 0.002150).  Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 0.475001 \tValidation Loss: 0.002143\n",
      "Validation loss decreased (0.002150 --> 0.002143).  Saving model ...\n",
      "Epoch: 29 \tTraining Loss: 0.474937 \tValidation Loss: 0.002138\n",
      "Validation loss decreased (0.002143 --> 0.002138).  Saving model ...\n",
      "Epoch: 30 \tTraining Loss: 0.474900 \tValidation Loss: 0.002133\n",
      "Validation loss decreased (0.002138 --> 0.002133).  Saving model ...\n",
      "Epoch: 31 \tTraining Loss: 0.474990 \tValidation Loss: 0.002123\n",
      "Validation loss decreased (0.002133 --> 0.002123).  Saving model ...\n",
      "Epoch: 32 \tTraining Loss: 0.474874 \tValidation Loss: 0.002122\n",
      "Validation loss decreased (0.002123 --> 0.002122).  Saving model ...\n",
      "Epoch: 33 \tTraining Loss: 0.474915 \tValidation Loss: 0.002112\n",
      "Validation loss decreased (0.002122 --> 0.002112).  Saving model ...\n",
      "Epoch: 34 \tTraining Loss: 0.474862 \tValidation Loss: 0.002103\n",
      "Validation loss decreased (0.002112 --> 0.002103).  Saving model ...\n",
      "Epoch: 35 \tTraining Loss: 0.474767 \tValidation Loss: 0.002091\n",
      "Validation loss decreased (0.002103 --> 0.002091).  Saving model ...\n",
      "Epoch: 36 \tTraining Loss: 0.474678 \tValidation Loss: 0.002084\n",
      "Validation loss decreased (0.002091 --> 0.002084).  Saving model ...\n",
      "Epoch: 37 \tTraining Loss: 0.474636 \tValidation Loss: 0.002087\n",
      "Epoch: 38 \tTraining Loss: 0.474507 \tValidation Loss: 0.002141\n",
      "Epoch: 39 \tTraining Loss: 0.473945 \tValidation Loss: 0.002163\n",
      "Epoch: 40 \tTraining Loss: 0.473816 \tValidation Loss: 0.002178\n",
      "Epoch: 41 \tTraining Loss: 0.473770 \tValidation Loss: 0.002162\n",
      "Epoch: 42 \tTraining Loss: 0.473637 \tValidation Loss: 0.002151\n",
      "Epoch: 43 \tTraining Loss: 0.473769 \tValidation Loss: 0.002159\n",
      "Epoch: 44 \tTraining Loss: 0.473857 \tValidation Loss: 0.002180\n",
      "Epoch: 45 \tTraining Loss: 0.474298 \tValidation Loss: 0.002166\n",
      "Epoch: 46 \tTraining Loss: 0.474048 \tValidation Loss: 0.002122\n",
      "Epoch: 47 \tTraining Loss: 0.473995 \tValidation Loss: 0.002115\n",
      "Epoch: 48 \tTraining Loss: 0.474073 \tValidation Loss: 0.002114\n",
      "Epoch: 49 \tTraining Loss: 0.474281 \tValidation Loss: 0.002131\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer,criterion,train_data,val_data,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1c048",
   "metadata": {},
   "source": [
    "**Visualizamos los parametros del mejor modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "208e99b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight tensor([[ 7.4574e-02,  2.0312e-01,  2.1750e-01, -1.3612e-01,  2.9779e-01,\n",
      "          2.7565e-01, -1.6340e-01, -1.9764e+00,  1.3271e+00,  1.0451e+00,\n",
      "          1.7439e-01, -1.1671e-01,  1.7104e-01,  1.2991e-01,  3.8204e-01,\n",
      "         -7.6393e-01, -5.1842e-02,  1.0509e+00,  1.2195e+00, -1.7928e-01],\n",
      "        [ 5.2211e-02, -1.9920e-01, -1.2577e-01,  9.1154e-02,  1.6469e-01,\n",
      "          1.7827e-01, -1.2934e-01,  2.4912e-01, -1.6447e-01,  5.9074e-02,\n",
      "          1.9445e-01, -4.4041e-02,  9.5997e-02, -1.6958e-02, -3.5822e-02,\n",
      "          2.0804e-01,  2.6692e-01, -3.0354e-02, -3.2887e-01,  2.0192e-01],\n",
      "        [-6.7945e-02, -2.0129e-01, -6.6339e-02,  8.1698e-02, -2.3795e-02,\n",
      "          3.2022e-02, -3.2879e-02, -2.4122e-01, -2.0079e-01, -1.8763e-01,\n",
      "          7.4315e-02, -3.6408e-02, -1.5757e-01, -1.4638e-01,  8.2392e-02,\n",
      "          1.3684e-01,  1.4555e-01,  1.7231e-01,  2.4622e-01, -1.0315e-01],\n",
      "        [-8.5410e-02,  1.1774e-01,  7.0145e-02, -1.4409e-01,  3.1980e-02,\n",
      "          1.5980e-03, -4.5653e-02,  8.9581e-01, -5.4298e-01, -7.6406e-02,\n",
      "          1.5259e-01, -6.8234e-02,  1.4562e-01, -1.9456e-01,  1.7014e-03,\n",
      "          3.0927e-01,  1.3667e-02, -5.9952e-01, -4.5805e-01,  2.0222e-01],\n",
      "        [ 1.9392e-01, -1.1229e-01, -1.3391e-01,  9.1321e-02, -1.7412e-01,\n",
      "         -1.8826e-02, -5.3122e-02,  2.8762e-01, -1.2880e-01,  1.5317e-01,\n",
      "          2.5877e-01, -1.3648e-01, -1.0546e-01, -1.6033e-01,  1.9229e-01,\n",
      "          1.7537e-01,  2.8764e-01, -1.7504e-01, -2.4697e-01,  1.5580e-01],\n",
      "        [-8.6185e-02,  6.6998e-02,  2.2484e-01,  2.3275e-01,  1.7109e-01,\n",
      "          9.9150e-03, -1.8030e-01,  3.1130e-01,  5.8642e-02,  1.7832e-01,\n",
      "          1.6866e-01,  2.4534e-02,  5.6465e-02,  2.2422e-02,  1.7059e-01,\n",
      "          1.0226e-01, -1.6601e-02, -1.7696e-01, -2.8319e-01, -1.6401e-01],\n",
      "        [ 1.9709e-01, -4.0040e-03, -2.0786e-01, -7.5179e-02,  8.8234e-02,\n",
      "         -1.6951e-01,  9.6998e-02, -1.9533e-01, -2.5689e-01,  2.9485e-02,\n",
      "          1.6437e-01,  3.8445e-02,  7.5331e-02, -6.6414e-02,  1.6225e-03,\n",
      "          3.5224e-02, -1.1967e-01, -7.1893e-01, -7.5505e-01, -1.2909e-02],\n",
      "        [ 7.1665e-03,  1.4550e-01, -2.3284e-01,  1.8914e-01,  1.4069e-01,\n",
      "          1.0580e-01, -2.1506e-02, -2.6316e-01, -3.0769e-02, -7.4028e-02,\n",
      "         -1.3757e-01, -2.1170e-01,  1.5270e-02,  1.4745e-01,  1.2528e-02,\n",
      "         -3.7500e-02, -2.2480e-01,  1.7981e-01,  2.1994e-01,  5.2570e-02],\n",
      "        [ 1.5589e-02, -1.9567e-01, -5.8856e-02,  1.7369e-01, -8.4113e-02,\n",
      "         -9.4285e-02,  1.9783e-01,  2.5389e-01,  1.7821e-01,  5.8434e-02,\n",
      "         -1.8345e-03,  2.0394e-03, -6.0414e-02, -5.4006e-02,  2.0719e-01,\n",
      "         -5.1580e-02,  1.5728e-01, -1.5122e-01, -1.6485e-01, -7.9922e-02],\n",
      "        [-1.0165e-01,  1.6599e-01,  2.1624e-01, -1.0065e-01,  1.0567e-01,\n",
      "         -9.0608e-02,  1.7512e-01,  1.6802e-01, -2.1922e-01, -1.6792e-01,\n",
      "         -7.5278e-02, -1.7139e-01, -1.9519e-01,  7.3560e-02,  2.1768e-01,\n",
      "          1.7565e-01,  2.6025e-01, -2.8676e-01, -9.7168e-02, -5.0958e-02],\n",
      "        [-5.3156e-02,  2.3604e-02, -1.4249e-01,  7.6698e-02, -1.1021e-01,\n",
      "          1.7772e-02,  6.8742e-02,  7.3443e-01, -2.0295e-01, -1.4077e-01,\n",
      "          1.0878e-01, -6.4593e-04,  1.3555e-01, -3.3490e-02,  8.3119e-03,\n",
      "          2.9977e-01, -4.5355e-02, -3.2123e-01, -6.5352e-01,  1.3563e-01],\n",
      "        [-1.5357e-01,  1.5728e-01,  1.9296e-01,  1.9971e-01,  1.6319e-02,\n",
      "         -7.4019e-02, -3.8472e-03,  2.7513e-01, -1.8703e-01,  2.1224e-01,\n",
      "         -2.5601e-02, -4.1357e-02,  4.6907e-02,  8.8729e-03,  9.3022e-02,\n",
      "          4.0843e-01, -7.2272e-03, -5.7873e-02, -3.4368e-01, -4.7562e-02],\n",
      "        [ 5.9380e-02, -1.4018e-01, -1.5961e-01, -1.8953e-01, -1.4796e-01,\n",
      "         -6.6493e-02,  1.9003e-01,  2.0766e-01, -1.0809e-02, -1.8136e-01,\n",
      "          6.6465e-02, -1.6236e-01,  2.0080e-01, -3.0379e-02,  1.9372e-01,\n",
      "          1.6601e-01,  2.4948e-01,  3.2136e-03, -3.8770e-01,  6.8126e-02],\n",
      "        [ 3.8489e-02, -1.0587e-01, -4.7934e-02,  1.9473e-01,  3.4452e-02,\n",
      "         -9.8302e-02,  1.7733e-01,  2.1982e-01,  1.1391e-01, -2.2195e-01,\n",
      "          1.0008e-01,  1.5933e-01, -4.7360e-02, -2.0493e-01,  1.0901e-01,\n",
      "          2.5267e-02,  1.3743e-01, -1.7565e-01, -3.0275e-01,  2.1595e-01]])\n",
      "fc1.bias tensor([ 1.1530,  0.0084,  0.0155, -0.3842,  0.0823, -0.1228,  0.1137,  0.1837,\n",
      "        -0.1698,  0.0527, -0.1674, -0.0587, -0.2157, -0.0183])\n",
      "fc2.weight tensor([[ 8.9023e-02,  5.2479e-02,  2.1147e-02,  8.7400e-02, -2.4618e-03,\n",
      "         -8.6853e-02, -1.7989e-01, -3.2767e-02,  8.6435e-02, -6.8133e-02,\n",
      "          1.9624e-03,  5.7980e-02, -1.2660e-02,  2.4419e-02],\n",
      "        [ 3.0651e-02, -1.1998e-03, -3.1259e-02, -4.2466e-02, -6.5909e-02,\n",
      "          6.6772e-02, -1.0481e-01,  1.0937e-01, -8.1616e-03, -2.1726e-02,\n",
      "          1.5201e-01,  1.4179e-02,  4.8302e-02,  6.9294e-02],\n",
      "        [ 1.6909e-01,  8.8303e-02, -3.1644e-02,  2.0585e-01, -9.5928e-02,\n",
      "          5.9305e-03, -2.2406e-02, -5.6632e-02,  1.6005e-03,  3.9571e-02,\n",
      "          9.7675e-02, -3.4836e-02,  1.4223e-03, -4.8056e-03],\n",
      "        [-2.5290e-01,  3.5987e-02,  1.1744e-02,  6.7855e-03, -4.3244e-02,\n",
      "         -3.6041e-02, -1.3120e-01,  8.5129e-02,  3.2852e-02, -4.0751e-02,\n",
      "         -1.3629e-01, -1.9840e-02,  7.0181e-03, -9.3719e-02],\n",
      "        [-3.8040e-01, -2.7453e-02,  3.1297e-02, -2.5482e-02, -6.3456e-02,\n",
      "         -7.8678e-02,  9.8933e-02,  4.5242e-02,  4.9936e-02,  7.4656e-02,\n",
      "          1.9356e-02,  7.7641e-02, -3.7936e-02, -4.2011e-03],\n",
      "        [-1.1955e-01,  3.2790e-02,  3.4779e-02, -1.2050e-01, -5.1428e-02,\n",
      "         -8.0755e-02,  8.2471e-02,  1.9721e-02, -6.7861e-02,  2.8764e-03,\n",
      "         -1.9301e-01,  2.6146e-02,  1.1536e-02,  1.5962e-02],\n",
      "        [-1.7089e-01, -8.1898e-03,  7.3838e-03,  5.9774e-02,  1.1248e-01,\n",
      "         -3.1904e-03,  5.7161e-02,  7.4141e-02,  8.0798e-03, -6.5103e-02,\n",
      "         -1.8364e-03, -2.0058e-04,  2.3044e-02,  1.7177e-02],\n",
      "        [-4.4475e-01, -6.4070e-04,  6.7370e-02, -7.1576e-03,  3.0738e-02,\n",
      "          7.4510e-03, -6.5901e-02, -1.0107e-01,  1.3444e-02, -6.4197e-02,\n",
      "         -1.1842e-01, -3.6633e-02,  4.4824e-03, -2.5557e-03]])\n",
      "fc2.bias tensor([-0.2358, -0.1236, -0.0501, -0.1477, -0.0107,  0.1738, -0.0361, -0.1690])\n",
      "fc3.weight tensor([[ 0.1966, -0.0228, -0.0612, -0.1001,  0.2365, -0.1722,  0.2891, -0.0779],\n",
      "        [ 0.2026, -0.0543, -0.1101, -0.0998,  0.0962, -0.0906,  0.1967, -0.2292]])\n",
      "fc3.bias tensor([0.3399, 0.3000])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87f95f4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 784]' is invalid for input of size 60",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m], data[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Put each image into a vector\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m784\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Do the forward pass and get the predictions\u001b[39;00m\n\u001b[0;32m     10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[-1, 784]' is invalid for input of size 60"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total, correct =0,0\n",
    "for i, data in enumerate(test_data, 0):\n",
    "    inputs, labels = data[0], data[1]\n",
    "    \n",
    "    # Put each image into a vector\n",
    "    inputs = inputs.view(-1, 784)\n",
    "    \n",
    "    # Do the forward pass and get the predictions\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    _, outputs = torch.max(outputs.data, 1) #mayor valor entre los dígitos.\n",
    "    total += labels.size(0)\n",
    "    correct += (outputs == labels).sum().item()\n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ebc0a",
   "metadata": {},
   "source": [
    "### Escoger una muestra aleatoria del DataSet\n",
    "Vamos a tomar una muestra aleatoria con la función Sample y utilizar el modelo anterior para poder predecir el semintimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "69fd33bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>0.229763</td>\n",
       "      <td>0.052751</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.215128</td>\n",
       "      <td>0.265385</td>\n",
       "      <td>0.050256</td>\n",
       "      <td>2.859533</td>\n",
       "      <td>12.289489</td>\n",
       "      <td>0.871022</td>\n",
       "      <td>0.333922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186087</td>\n",
       "      <td>0.026891</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>1.329167</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>6.804688</td>\n",
       "      <td>6.460938</td>\n",
       "      <td>0.218518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "524  0.229763  0.052751  0.246154  0.215128  0.265385  0.050256  2.859533   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...   meanfun    minfun    maxfun  \\\n",
       "524  12.289489  0.871022  0.333922  ...  0.186087  0.026891  0.262295   \n",
       "\n",
       "      meandom   mindom    maxdom   dfrange   modindx  happy  sad  \n",
       "524  1.329167  0.34375  6.804688  6.460938  0.218518      0    0  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.concat([X,y],axis = 1)\n",
    "\n",
    "sample = df_all.sample(1)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "66c48ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_y = df_all[['happy','sad']]\n",
    "sample_x = df_all.drop(columns = ['happy','sad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ab41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sec=MyDataset(sample_x, sample_y)\n",
    "\n",
    "\n",
    "sample_data=DataLoader(\n",
    "    sample_sec,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=None,\n",
    "    pin_memory=False,\n",
    " )\n",
    "\n",
    "criterion= nn.MSELoss()\n",
    "for data, target in sample_data:\n",
    "  output=model(data)\n",
    "\n",
    "print((output))\n",
    "print((sample[['happy','sad']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
